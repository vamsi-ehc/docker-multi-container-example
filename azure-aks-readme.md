# â˜ï¸ Azure AKS Deployment Guide

Complete guide to deploy your multi-container application on **Azure Kubernetes Service (AKS)** with and without Istio service mesh.

---

## ğŸŒ Traffic Flow Architecture

### Overall Azure AKS Setup

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INTERNET                                    â”‚
â”‚                    (Users & External Requests)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  Azure Public IP (ALB)â”‚
                   â”‚  (frontend.local)     â”‚
                   â”‚  (api.local)          â”‚
                   â”‚  (health.local)       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                              â”‚
        â†“                                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  INGRESS-NGINX       â”‚                   â”‚  ISTIO INGRESSGATEWAYâ”‚
â”‚  (Without Istio)     â”‚                   â”‚  (With Istio)        â”‚
â”‚  Routes HTTP/HTTPS  â”‚                   â”‚ Routes + Policies    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                                              â†“
        â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”´â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                      â”‚                    â”‚   â”‚              â”‚
        â†“                      â†“                    â†“   â†“              â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Frontend   â”‚    â”‚  Todo App    â”‚    â”‚  Calculator API         â”‚
   â”‚  Service    â”‚    â”‚  Service     â”‚    â”‚  Health Monitor Service â”‚
   â”‚  (Port 80)  â”‚    â”‚  (Port 3000) â”‚    â”‚                         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                    â†“                      â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Frontend   â”‚    â”‚  Todo App    â”‚    â”‚  Calculator   â”‚ Health   â”‚
   â”‚  Pod (2x)   â”‚    â”‚  Pod (2x)    â”‚    â”‚  Pod (2x)     â”‚ Pod (1x) â”‚
   â”‚ +Sidecar*   â”‚    â”‚ +Sidecar*    â”‚    â”‚ +Sidecar*     â”‚+Sidecar* â”‚
   â”‚ (if Istio)  â”‚    â”‚ (if Istio)   â”‚    â”‚ (if Istio)    â”‚(if Istio)â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                    â†“                      â†“
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MongoDB Service  â”‚
                    â”‚   (Port 27017)     â”‚
                    â”‚   Replica: 1       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MongoDB Pod      â”‚
                    â”‚   (No Sidecar)     â”‚
                    â”‚   Persistent Vol   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **Note:** `*Sidecar` = Envoy proxy (only with Istio)

---

## ğŸ“‹ Prerequisites

- **Azure Account** with active subscription
- **Azure CLI** installed ([Download](https://docs.microsoft.com/en-us/cli/azure/install-azure-cli))
- **kubectl** installed
- **Docker** installed locally
- **Helm 3** (optional, for Istio installation)
- Sufficient Azure credits/quota

Verify installations:
```bash
az --version
kubectl version --client
docker --version
```

---

## ğŸ” Step 1: Azure Login & Setup

Login to Azure:
```bash
az login
```

Set your subscription (if you have multiple):
```bash
# List subscriptions
az account list --output table

# Set active subscription
az account set --subscription "<SUBSCRIPTION_ID>"
```

Create a resource group:
```bash
az group create \
  --name multi-container-rg \
  --location eastus
```

> ğŸ’¡ **Available regions**: `eastus`, `westus2`, `westeurope`, `southeastasia`, etc.

---

## ğŸ“¦ Step 2: Create Azure Container Registry (ACR)

Create ACR to store your Docker images:
```bash
az acr create \
  --resource-group multi-container-rg \
  --name multicontaineracr \
  --sku Basic \
  --location eastus
```

> âš ï¸ ACR name must be **globally unique** and lowercase. Adjust `multicontaineracr` if taken.

Login to ACR:
```bash
az acr login --name multicontaineracr
```

Get ACR login server:
```bash
az acr show \
  --name multicontaineracr \
  --query loginServer \
  --output tsv
```

Output: `multicontaineracr.azurecr.io` (save this!)

---

## ğŸ—ï¸ Step 3: Build & Push Docker Images to ACR

Tag and push all images:

```bash
# Set ACR name variable
$ACR_NAME = "multicontaineracr.azurecr.io"

# Build and tag frontend
docker build -t frontend:latest ./frontend
docker tag frontend:latest $ACR_NAME/frontend:latest
docker push $ACR_NAME/frontend:latest

# Build and tag todo-app
docker build -t todo-app:latest ./app
docker tag todo-app:latest $ACR_NAME/todo-app:latest
docker push $ACR_NAME/todo-app:latest

# Build and tag calculator-api
docker build -t calculator-api:latest ./calculator-api
docker tag calculator-api:latest $ACR_NAME/calculator-api:latest
docker push $ACR_NAME/calculator-api:latest

# Build and tag health-monitor
docker build -t health-monitor:latest ./health-monitor
docker tag health-monitor:latest $ACR_NAME/health-monitor:latest
docker push $ACR_NAME/health-monitor:latest
```

Verify images:
```bash
az acr repository list --name multicontaineracr --output table
```

---

## âš™ï¸ Step 4: Create AKS Cluster

### Option A: Without Istio (Standard AKS)

Create basic AKS cluster:
```bash
az aks create \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --node-count 2 \
  --node-vm-size Standard_B2s \
  --enable-managed-identity \
  --attach-acr multicontaineracr \
  --generate-ssh-keys \
  --location eastus
```

### Option B: With Istio (AKS with Istio Add-on)

Create AKS with Istio service mesh add-on:
```bash
az aks create \
  --resource-group multi-container-rg \
  --name multi-container-aks-istio \
  --node-count 2 \
  --node-vm-size Standard_B2s \
  --enable-managed-identity \
  --attach-acr multicontaineracr \
  --enable-asm \
  --generate-ssh-keys \
  --location eastus
```

> ğŸ“ `--enable-asm` enables the **Azure Service Mesh** (Istio-based managed add-on)

â±ï¸ Cluster creation takes **5-10 minutes**.

---

## ğŸ”— Step 5: Connect to AKS Cluster

Get cluster credentials:
```bash
# For standard AKS
az aks get-credentials \
  --resource-group multi-container-rg \
  --name multi-container-aks

# For AKS with Istio
az aks get-credentials \
  --resource-group multi-container-rg \
  --name multi-container-aks-istio
```

Verify connection:
```bash
kubectl cluster-info
kubectl get nodes
```

---

# ğŸš¢ Deployment Path A: Without Istio (Standard Kubernetes)

## ï¿½ Traffic Flow (Without Istio)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER BROWSER REQUEST                             â”‚
â”‚              http://frontend.local/todos                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Azure Load       â”‚
                     â”‚ Balancer (ALB)   â”‚
                     â”‚ Public IP:       â”‚
                     â”‚ 40.xx.xx.xx      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                 DNS Resolution: frontend.local
                      â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ INGRESS-NGINX CONTROLLER    â”‚
          â”‚ Namespace: ingress-nginx    â”‚
          â”‚ Service Type: LoadBalancer  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ INGRESS RESOURCE         â”‚
           â”‚ spec:                    â”‚
           â”‚ - hosts:                 â”‚
           â”‚   - frontend.local       â”‚
           â”‚   - api.local            â”‚
           â”‚   - health.local         â”‚
           â”‚ - backend services       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                 â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend   â”‚  â”‚ Todo App   â”‚  â”‚Calculatorâ”‚  â”‚  Health    â”‚
â”‚ Service    â”‚  â”‚ Service    â”‚  â”‚  API     â”‚  â”‚  Monitor   â”‚
â”‚ ClusterIP  â”‚  â”‚ ClusterIP  â”‚  â”‚ Service  â”‚  â”‚  Service   â”‚
â”‚ :80        â”‚  â”‚ :3000      â”‚  â”‚ :5000    â”‚  â”‚  :4000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                 â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend   â”‚  â”‚ Todo App   â”‚  â”‚Calculatorâ”‚  â”‚  Health    â”‚
â”‚ Pod-1      â”‚  â”‚ Pod-1      â”‚  â”‚  API     â”‚  â”‚  Monitor   â”‚
â”‚ Pod-2      â”‚  â”‚ Pod-2      â”‚  â”‚  Pod-1   â”‚  â”‚  Pod-1     â”‚
â”‚ (1/1)      â”‚  â”‚ (1/1)      â”‚  â”‚  Pod-2   â”‚  â”‚  (1/1)     â”‚
â”‚            â”‚  â”‚            â”‚  â”‚  (1/1)   â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                 â†“              â†“ (both connect to DB)
    â”‚                 â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ MongoDB Service      â”‚
            â”‚ ClusterIP :27017     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ MongoDB Pod          â”‚
            â”‚ Persistent Storage   â”‚
            â”‚ (Kubernetes PVC)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Path A - Network Path Example

**Request Flow for:** `http://api.local/todos`

```
1. Browser â†’ ALB (40.xx.xx.xx)
   â”œâ”€ DNS lookup: api.local â†’ 40.xx.xx.xx
   â””â”€ HTTP GET /todos

2. ALB â†’ INGRESS-NGINX
   â””â”€ Forwards to ingress controller pod(s)

3. INGRESS-NGINX â†’ Service Routing
   â”œâ”€ Matches host: api.local
   â”œâ”€ Matches path: /todos
   â””â”€ Routes to: todo-app service

4. Service â†’ Pod Load Balancing
   â”œâ”€ Round-robin to todo-app pod-1 or pod-2
   â””â”€ ClusterIP :3000 â†’ Pod Port 3000

5. Pod â†’ Database Query
   â”œâ”€ App connects to todo-database:27017
   â”œâ”€ MongoDB service resolves DNS
   â””â”€ Reaches MongoDB pod via kube-proxy

6. Response â†’ Browser
   â”œâ”€ MongoDB returns data
   â”œâ”€ Todo App processes & returns JSON
   â”œâ”€ INGRESS-NGINX forwards response
   â”œâ”€ ALB sends to client
   â””â”€ Browser renders todos
```

---

## ï¿½ğŸ“ Step 6A: Create Kubernetes Manifests (Without Istio)

Create `k8s/aks-deployment.yaml`:

```yaml
# MongoDB
apiVersion: v1
kind: Service
metadata:
  name: todo-database
spec:
  type: ClusterIP
  ports:
  - port: 27017
    targetPort: 27017
  selector:
    app: mongo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
    spec:
      containers:
      - name: mongo
        image: mongo:latest
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: admin
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: mongo-storage
          mountPath: /data/db
      volumes:
      - name: mongo-storage
        persistentVolumeClaim:
          claimName: mongo-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongo-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: default
---
# Frontend
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: frontend
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: multicontaineracr.azurecr.io/frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Todo App
apiVersion: v1
kind: Service
metadata:
  name: todo-app
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
  selector:
    app: todo-app
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: todo-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: todo-app
  template:
    metadata:
      labels:
        app: todo-app
    spec:
      containers:
      - name: todo-app
        image: multicontaineracr.azurecr.io/todo-app:latest
        ports:
        - containerPort: 3000
        env:
        - name: MONGO_URI
          value: "mongodb://admin:password@todo-database:27017/todos?authSource=admin"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Calculator API
apiVersion: v1
kind: Service
metadata:
  name: calculator-api
spec:
  type: ClusterIP
  ports:
  - port: 5000
    targetPort: 5000
  selector:
    app: calculator-api
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: calculator-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: calculator-api
  template:
    metadata:
      labels:
        app: calculator-api
    spec:
      containers:
      - name: calculator-api
        image: multicontaineracr.azurecr.io/calculator-api:latest
        ports:
        - containerPort: 5000
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Health Monitor
apiVersion: v1
kind: Service
metadata:
  name: health-monitor
spec:
  type: ClusterIP
  ports:
  - port: 4000
    targetPort: 4000
  selector:
    app: health-monitor
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: health-monitor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: health-monitor
  template:
    metadata:
      labels:
        app: health-monitor
    spec:
      containers:
      - name: health-monitor
        image: multicontaineracr.azurecr.io/health-monitor:latest
        ports:
        - containerPort: 4000
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
```

> âš ï¸ Replace `multicontaineracr.azurecr.io` with your ACR login server!

Deploy:
```bash
kubectl apply -f k8s/aks-deployment.yaml
```

Verify:
```bash
kubectl get pods
kubectl get svc
```

---

## ğŸŒ Step 7A: Setup Ingress Controller (Without Istio)

Install NGINX Ingress Controller:
```bash
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update

helm install ingress-nginx ingress-nginx/ingress-nginx \
  --namespace ingress-nginx \
  --create-namespace \
  --set controller.service.annotations."service\.beta\.kubernetes\.io/azure-load-balancer-health-probe-request-path"=/healthz
```

Wait for external IP:
```bash
kubectl get svc -n ingress-nginx -w
```

Get the **EXTERNAL-IP** (e.g., `20.12.34.56`).

Create `k8s/aks-ingress.yaml`:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  rules:
  - host: frontend.yourapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              number: 80
  - host: api.yourapp.com
    http:
      paths:
      - path: /calc
        pathType: Prefix
        backend:
          service:
            name: calculator-api
            port:
              number: 5000
      - path: /
        pathType: Prefix
        backend:
          service:
            name: todo-app
            port:
              number: 3000
  - host: health.yourapp.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: health-monitor
            port:
              number: 4000
```

Apply:
```bash
kubectl apply -f k8s/aks-ingress.yaml
```

---

## ğŸŒ Step 8A: Configure DNS (Without Istio)

### Option 1: Use Azure DNS

Create DNS zone:
```bash
az network dns zone create \
  --resource-group multi-container-rg \
  --name yourapp.com
```

Add A records pointing to ingress external IP:
```bash
# Get ingress IP
$INGRESS_IP = kubectl get svc -n ingress-nginx ingress-nginx-controller -o jsonpath='{.status.loadBalancer.ingress[0].ip}'

# Create DNS records
az network dns record-set a add-record \
  --resource-group multi-container-rg \
  --zone-name yourapp.com \
  --record-set-name frontend \
  --ipv4-address $INGRESS_IP

az network dns record-set a add-record \
  --resource-group multi-container-rg \
  --zone-name yourapp.com \
  --record-set-name api \
  --ipv4-address $INGRESS_IP

az network dns record-set a add-record \
  --resource-group multi-container-rg \
  --zone-name yourapp.com \
  --record-set-name health \
  --ipv4-address $INGRESS_IP
```

### Option 2: Use Public IP with DNS Label

```bash
# Get public IP resource name
az network public-ip list \
  --resource-group MC_multi-container-rg_multi-container-aks_eastus \
  --query "[?contains(name, 'kubernetes')].name" \
  --output tsv

# Set DNS name label
az network public-ip update \
  --resource-group MC_multi-container-rg_multi-container-aks_eastus \
  --name <PUBLIC_IP_NAME> \
  --dns-name multicontainerapp
```

Access via: `multicontainerapp.eastus.cloudapp.azure.com`

### Option 3: Use Hosts File (Testing Only)

Edit hosts file with ingress external IP:
```
20.12.34.56 frontend.yourapp.com
20.12.34.56 api.yourapp.com
20.12.34.56 health.yourapp.com
```

---

## âœ… Step 9A: Test Application (Without Istio)

Access your application:
- **Frontend**: http://frontend.yourapp.com
- **Todo API**: http://api.yourapp.com/todos
- **Calculator**: http://api.yourapp.com/calc
- **Health**: http://health.yourapp.com

---

# ğŸ•¸ï¸ Deployment Path B: With Istio Service Mesh

## ğŸ“ Step 6B: Enable Istio in AKS

If you created cluster without `--enable-asm`, enable it:
```bash
az aks mesh enable \
  --resource-group multi-container-rg \
  --name multi-container-aks-istio
```

Verify Istio installation:
```bash
kubectl get pods -n aks-istio-system
```

You should see:
- `istiod-*` (control plane)
- `istio-ingressgateway-*`

---

# ğŸ•¸ï¸ Deployment Path B: With Istio Service Mesh

## ğŸ”„ Traffic Flow (With Istio)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER BROWSER REQUEST                             â”‚
â”‚              http://frontend.local/todos                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Azure Load       â”‚
                     â”‚ Balancer (ALB)   â”‚
                     â”‚ Public IP:       â”‚
                     â”‚ 40.yy.yy.yy      â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
                 DNS Resolution: frontend.local
                      â†“
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ ISTIO INGRESSGATEWAY        â”‚
          â”‚ Namespace: istio-system     â”‚
          â”‚ Service Type: LoadBalancer  â”‚
          â”‚ (Envoy Proxy)               â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ GATEWAY RESOURCE         â”‚
           â”‚ spec:                    â”‚
           â”‚ - servers:               â”‚
           â”‚   - port: 80             â”‚
           â”‚   - hosts:               â”‚
           â”‚     - frontend.local     â”‚
           â”‚     - api.local          â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ VIRTUALSERVICE ROUTING   â”‚
           â”‚ Advanced Traffic Rules:  â”‚
           â”‚ - Retries                â”‚
           â”‚ - Timeouts               â”‚
           â”‚ - Circuit breakers       â”‚
           â”‚ - Weighted routing       â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â†“                 â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend   â”‚  â”‚ Todo App   â”‚  â”‚Calculatorâ”‚  â”‚  Health    â”‚
â”‚ Service    â”‚  â”‚ Service    â”‚  â”‚  API     â”‚  â”‚  Monitor   â”‚
â”‚ ClusterIP  â”‚  â”‚ ClusterIP  â”‚  â”‚ Service  â”‚  â”‚  Service   â”‚
â”‚ :80        â”‚  â”‚ :3000      â”‚  â”‚ :5000    â”‚  â”‚  :4000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                 â†“              â†“                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend   â”‚  â”‚ Todo App   â”‚  â”‚Calculatorâ”‚  â”‚  Health    â”‚
â”‚ Pod-1      â”‚  â”‚ Pod-1      â”‚  â”‚  API     â”‚  â”‚  Monitor   â”‚
â”‚ Envoy â—    â”‚  â”‚ Envoy â—    â”‚  â”‚  Pod-1   â”‚  â”‚  Pod-1     â”‚
â”‚ App â—      â”‚  â”‚ App â—      â”‚  â”‚  Envoy â—â”‚  â”‚  Envoy â—   â”‚
â”‚ (2/2)      â”‚  â”‚ (2/2)      â”‚  â”‚  App â—  â”‚  â”‚  App â—     â”‚
â”‚ Pod-2      â”‚  â”‚ Pod-2      â”‚  â”‚  (2/2)  â”‚  â”‚  (2/2)     â”‚
â”‚ Envoy â—    â”‚  â”‚ Envoy â—    â”‚  â”‚  Pod-2   â”‚  â”‚            â”‚
â”‚ App â—      â”‚  â”‚ App â—      â”‚  â”‚  Envoy â— â”‚  â”‚            â”‚
â”‚ (2/2)      â”‚  â”‚ (2/2)      â”‚  â”‚  App â—  â”‚  â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“                 â†“              â†“                â†“
    â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚      â”‚  DESTINATION RULES   â”‚ â”‚
    â”‚      â”‚  & PEER AUTH         â”‚ â”‚
    â”‚      â”‚ - mTLS: STRICT       â”‚ â”‚
    â”‚      â”‚ - Retries: 3x        â”‚ â”‚
    â”‚      â”‚ - Timeout: 10s       â”‚ â”‚
    â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚                               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ MongoDB Service      â”‚
            â”‚ ClusterIP :27017     â”‚
            â”‚ (No Sidecar)         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ MongoDB Pod          â”‚
            â”‚ Persistent Storage   â”‚
            â”‚ (Kubernetes PVC)     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Path B - Network Path Example with Istio

**Request Flow for:** `http://api.local/todos`

```
1. Browser â†’ Istio Ingress Gateway (40.yy.yy.yy)
   â”œâ”€ DNS lookup: api.local â†’ 40.yy.yy.yy
   â””â”€ HTTP GET /todos

2. Istio Ingress Gateway (Envoy)
   â”œâ”€ Receives request
   â”œâ”€ Applies Gateway policies
   â””â”€ Evaluates VirtualService rules

3. VirtualService Routing (Policy Enforcement)
   â”œâ”€ Matches: host = api.local
   â”œâ”€ Matches: uri prefix = /todos
   â”œâ”€ Checks: Retry policy (3 attempts)
   â”œâ”€ Checks: Circuit breaker
   â”œâ”€ Routes to: todo-app destination
   â””â”€ Load balancing: Round-robin

4. Service â†’ Sidecar Proxy (Envoy)
   â”œâ”€ Pod's Envoy sidecar intercepts
   â”œâ”€ Service mesh applies policies:
   â”‚  â”œâ”€ Automatic mTLS encryption
   â”‚  â”œâ”€ Request timeout: 10s
   â”‚  â”œâ”€ Retry with exponential backoff
   â”‚  â””â”€ Circuit breaker on errors
   â””â”€ Forwards to app container

5. Pod â†’ Database Query (via Sidecar)
   â”œâ”€ Todo App sends to todo-database:27017
   â”œâ”€ Client Sidecar â†’ mTLS handshake
   â”œâ”€ Encrypted connection to MongoDB
   â””â”€ (MongoDB pod has NO sidecar - not in mesh)

6. Metrics Collection
   â”œâ”€ Envoy sidecars collect metrics
   â”‚  â”œâ”€ Request latency
   â”‚  â”œâ”€ Success/error rates
   â”‚  â””â”€ Traffic volume
   â”œâ”€ Sent to Prometheus (if enabled)
   â””â”€ Visualized in Kiali dashboard

7. Response â†’ Browser
   â”œâ”€ MongoDB returns data (unencrypted local)
   â”œâ”€ Sidecar applies egress rules
   â”œâ”€ Todo App processes & returns
   â”œâ”€ Sidecar compresses response
   â”œâ”€ Ingress gateway forwards to client
   â”œâ”€ ALB sends to browser
   â””â”€ Browser renders todos
```

### Istio Traffic Management Policies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       VIRTUALSERVICE TRAFFIC POLICIES                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  RETRY POLICY                                      â”‚
â”‚  â”œâ”€ attempts: 3                                    â”‚
â”‚  â”œâ”€ perTryTimeout: 5s                             â”‚
â”‚  â””â”€ retryOn: 5xx,reset-by-peer                    â”‚
â”‚                                                     â”‚
â”‚  TIMEOUT POLICY                                    â”‚
â”‚  â””â”€ timeout: 10s (per request)                    â”‚
â”‚                                                     â”‚
â”‚  WEIGHTED ROUTING (Canary)                         â”‚
â”‚  â”œâ”€ Version v1: 90% traffic                       â”‚
â”‚  â””â”€ Version v2: 10% traffic                       â”‚
â”‚                                                     â”‚
â”‚  CIRCUIT BREAKER (Destination Rule)                â”‚
â”‚  â”œâ”€ Max connections: 100                          â”‚
â”‚  â”œâ”€ Max pending requests: 50                      â”‚
â”‚  â”œâ”€ Max errors: 5                                 â”‚
â”‚  â””â”€ Eject time: 30s                               â”‚
â”‚                                                     â”‚
â”‚  mTLS (Peer Authentication)                        â”‚
â”‚  â”œâ”€ Mode: STRICT                                  â”‚
â”‚  â”œâ”€ Auto-encryption between all pods              â”‚
â”‚  â””â”€ Certificates managed by Istio                 â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ·ï¸ Step 6B: Enable Sidecar Injection

Label namespace for automatic sidecar injection:
```bash
kubectl label namespace default istio.io/rev=asm-1-20
```

> ğŸ“ AKS uses revision-based injection. Check your revision:
```bash
kubectl get mutatingwebhookconfigurations | grep istio
```

---

## ğŸ“¦ Step 8B: Deploy Application (With Istio)

Create `k8s/aks-istio-deployment.yaml`:

```yaml
# MongoDB (no sidecar needed)
apiVersion: v1
kind: Service
metadata:
  name: todo-database
spec:
  type: ClusterIP
  ports:
  - port: 27017
    name: mongo
  selector:
    app: mongo
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mongo
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongo
  template:
    metadata:
      labels:
        app: mongo
      annotations:
        sidecar.istio.io/inject: "false"  # No sidecar for database
    spec:
      containers:
      - name: mongo
        image: mongo:latest
        ports:
        - containerPort: 27017
        env:
        - name: MONGO_INITDB_ROOT_USERNAME
          value: admin
        - name: MONGO_INITDB_ROOT_PASSWORD
          value: password
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        volumeMounts:
        - name: mongo-storage
          mountPath: /data/db
      volumes:
      - name: mongo-storage
        persistentVolumeClaim:
          claimName: mongo-pvc
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mongo-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: default
---
# Frontend Service
apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: frontend
spec:
  type: ClusterIP
  ports:
  - port: 80
    targetPort: 80
    name: http
  selector:
    app: frontend
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
        version: v1
    spec:
      containers:
      - name: frontend
        image: multicontaineracr.azurecr.io/frontend:latest
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Todo App Service
apiVersion: v1
kind: Service
metadata:
  name: todo-app
  labels:
    app: todo-app
spec:
  type: ClusterIP
  ports:
  - port: 3000
    targetPort: 3000
    name: http
  selector:
    app: todo-app
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: todo-app
spec:
  replicas: 2
  selector:
    matchLabels:
      app: todo-app
  template:
    metadata:
      labels:
        app: todo-app
        version: v1
    spec:
      containers:
      - name: todo-app
        image: multicontaineracr.azurecr.io/todo-app:latest
        ports:
        - containerPort: 3000
        env:
        - name: MONGO_URI
          value: "mongodb://admin:password@todo-database:27017/todos?authSource=admin"
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Calculator API Service
apiVersion: v1
kind: Service
metadata:
  name: calculator-api
  labels:
    app: calculator-api
spec:
  type: ClusterIP
  ports:
  - port: 5000
    targetPort: 5000
    name: http
  selector:
    app: calculator-api
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: calculator-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: calculator-api
  template:
    metadata:
      labels:
        app: calculator-api
        version: v1
    spec:
      containers:
      - name: calculator-api
        image: multicontaineracr.azurecr.io/calculator-api:latest
        ports:
        - containerPort: 5000
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
# Health Monitor Service
apiVersion: v1
kind: Service
metadata:
  name: health-monitor
  labels:
    app: health-monitor
spec:
  type: ClusterIP
  ports:
  - port: 4000
    targetPort: 4000
    name: http
  selector:
    app: health-monitor
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: health-monitor
spec:
  replicas: 1
  selector:
    matchLabels:
      app: health-monitor
  template:
    metadata:
      labels:
        app: health-monitor
        version: v1
    spec:
      containers:
      - name: health-monitor
        image: multicontaineracr.azurecr.io/health-monitor:latest
        ports:
        - containerPort: 4000
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
```

Deploy:
```bash
kubectl apply -f k8s/aks-istio-deployment.yaml
```

Verify (each pod should show 2/2):
```bash
kubectl get pods
```

---

## ğŸŒ Step 9B: Configure Istio Gateway & VirtualServices

Create `k8s/aks-istio-gateway.yaml`:

```yaml
# Istio Gateway
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: app-gateway
spec:
  selector:
    istio: ingressgateway-external
  servers:
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - "frontend.yourapp.com"
    - "api.yourapp.com"
    - "health.yourapp.com"
---
# Frontend VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: frontend
spec:
  hosts:
  - "frontend.yourapp.com"
  gateways:
  - app-gateway
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: frontend
        port:
          number: 80
---
# API VirtualService (Todo + Calculator)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: api
spec:
  hosts:
  - "api.yourapp.com"
  gateways:
  - app-gateway
  http:
  - match:
    - uri:
        prefix: /calc
    route:
    - destination:
        host: calculator-api
        port:
          number: 5000
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: todo-app
        port:
          number: 3000
---
# Health Monitor VirtualService
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: health-monitor
spec:
  hosts:
  - "health.yourapp.com"
  gateways:
  - app-gateway
  http:
  - match:
    - uri:
        prefix: /
    route:
    - destination:
        host: health-monitor
        port:
          number: 4000
```

Apply:
```bash
kubectl apply -f k8s/aks-istio-gateway.yaml
```

---

## ğŸ›¡ï¸ Step 10B: Enable mTLS (Optional)

Create `k8s/aks-istio-mtls.yaml`:

```yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: default
spec:
  mtls:
    mode: STRICT
```

Apply:
```bash
kubectl apply -f k8s/aks-istio-mtls.yaml
```

---

## ğŸŒ Step 11B: Get Istio Gateway External IP

Get external IP:
```bash
kubectl get svc -n aks-istio-ingress
```

Look for `istio-ingressgateway-external` service EXTERNAL-IP.

Configure DNS (same as Step 8A) but use the Istio gateway IP instead.

---

## âœ… Step 12B: Test Application (With Istio)

Access your application:
- **Frontend**: http://frontend.yourapp.com
- **Todo API**: http://api.yourapp.com/todos
- **Calculator**: http://api.yourapp.com/calc
- **Health**: http://health.yourapp.com

---

## ğŸ“Š Step 13B: Enable Istio Observability

### Install Kiali (Service Mesh Dashboard)

```bash
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/kiali.yaml -n aks-istio-system
```

Expose Kiali:
```bash
kubectl port-forward svc/kiali -n aks-istio-system 20001:20001
```

Access: http://localhost:20001

### Install Prometheus & Grafana

```bash
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/prometheus.yaml -n aks-istio-system
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/grafana.yaml -n aks-istio-system
```

Expose Grafana:
```bash
kubectl port-forward svc/grafana -n aks-istio-system 3000:3000
```

Access: http://localhost:3000

### Install Jaeger (Distributed Tracing)

```bash
kubectl apply -f https://raw.githubusercontent.com/istio/istio/release-1.20/samples/addons/jaeger.yaml -n aks-istio-system
```

Expose Jaeger:
```bash
kubectl port-forward svc/tracing -n aks-istio-system 16686:80
```

Access: http://localhost:16686

---

## ğŸ“ˆ Monitoring with Azure Monitor

### Enable Container Insights

```bash
az aks enable-addons \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --addons monitoring
```

View logs:
```bash
az monitor log-analytics workspace list --output table
```

Access via Azure Portal â†’ Monitor â†’ Containers

---

### ğŸ“Š Istio Observability Visualization (Kiali Dashboard)

When using Istio, you can visualize your service mesh in Kiali:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     KIALI SERVICE MESH DASHBOARD                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Graph View:                                                    â”‚
â”‚                                                                 â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚  Frontend    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Todo App    â”‚              â”‚
â”‚         â”‚   (v1: 100%) â”‚ 95ms    â”‚  (v1: 90%)   â”‚              â”‚
â”‚         â”‚  âœ“ Healthy  â”‚          â”‚  âœ“ Healthy  â”‚              â”‚
â”‚         â”‚  90 req/sec  â”‚          â”‚  45 req/sec  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚               â”‚                          â”‚                      â”‚
â”‚               â”‚                          â–¼                      â”‚
â”‚               â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚               â”‚                   â”‚   MongoDB    â”‚              â”‚
â”‚               â”‚                   â”‚ :27017       â”‚              â”‚
â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  âœ“ Connected â”‚              â”‚
â”‚                                   â”‚  5ms latency â”‚              â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚         â”‚ Calculator   â”‚                                        â”‚
â”‚         â”‚  API (v2: ?) â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚         â”‚  (v1: 10%)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Health      â”‚              â”‚
â”‚         â”‚ âœ“ Healthy    â”‚ 2ms      â”‚  Monitor     â”‚              â”‚
â”‚         â”‚  20 req/sec  â”‚          â”‚ âœ“ Healthy    â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                 â”‚
â”‚  Metrics:                                                       â”‚
â”‚  â”œâ”€ Request Rate: 155 req/sec                                  â”‚
â”‚  â”œâ”€ Success Rate: 99.8%                                        â”‚
â”‚  â”œâ”€ P95 Latency: 150ms                                         â”‚
â”‚  â”œâ”€ mTLS Status: All connections encrypted âœ“                  â”‚
â”‚  â””â”€ Circuit Breaker: 0 trips                                   â”‚
â”‚                                                                 â”‚
â”‚  Tracing (Jaeger):                                              â”‚
â”‚  â”œâ”€ Request IDs tracked across services                        â”‚
â”‚  â”œâ”€ Distributed latency breakdown visible                      â”‚
â”‚  â”œâ”€ Service dependencies mapped                                â”‚
â”‚  â””â”€ Error traces available                                     â”‚
â”‚                                                                 â”‚
â”‚  Alerts:                                                        â”‚
â”‚  â”œâ”€ High Error Rate (>5%): NOT triggered                      â”‚
â”‚  â”œâ”€ Slow Response (>500ms): NOT triggered                     â”‚
â”‚  â”œâ”€ Pod Crash Loop: NOT triggered                             â”‚
â”‚  â””â”€ mTLS Issues: NOT triggered                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Metrics Collected by Istio Sidecars

```
PER REQUEST METRICS
â”œâ”€ Request Details
â”‚  â”œâ”€ Source Service: frontend
â”‚  â”œâ”€ Destination Service: todo-app
â”‚  â”œâ”€ Protocol: HTTP/1.1
â”‚  â”œâ”€ Method: GET /todos
â”‚  â”œâ”€ Status Code: 200
â”‚  â”œâ”€ Latency: 145ms
â”‚  â””â”€ Bytes Sent/Received: 1.2KB / 3.5KB
â”œâ”€ Retry Information
â”‚  â”œâ”€ Attempts: 1 (success on first try)
â”‚  â””â”€ Backoff: N/A
â”œâ”€ Circuit Breaker Status
â”‚  â””â”€ Status: OPEN/CLOSED (no trips)
â””â”€ Security
   â”œâ”€ TLS Version: TLSv1.3
   â”œâ”€ Cipher: TLS_AES_256_GCM_SHA384
   â””â”€ Certificate Valid Until: 2025-01-02

TIME SERIES METRICS
â”œâ”€ Request Rate (req/sec)
â”‚  â”œâ”€ Frontend â†’ Todo: 45 req/sec
â”‚  â”œâ”€ Frontend â†’ Calculator: 12 req/sec
â”‚  â””â”€ Todo â†’ MongoDB: 45 queries/sec
â”œâ”€ Latency Distribution
â”‚  â”œâ”€ p50 (median): 95ms
â”‚  â”œâ”€ p95: 150ms
â”‚  â”œâ”€ p99: 250ms
â”‚  â””â”€ p99.9: 400ms
â”œâ”€ Error Rate
â”‚  â”œâ”€ Total Errors: 0.2%
â”‚  â”œâ”€ 5xx Errors: 0.05%
â”‚  â”œâ”€ 4xx Errors: 0.15%
â”‚  â””â”€ Connection Errors: 0%
â””â”€ Throughput
   â”œâ”€ Inbound: 2.5 Mbps
   â”œâ”€ Outbound: 3.2 Mbps
   â””â”€ Total: 5.7 Mbps
```

---

## ğŸ”„ Update Application

### Update a Single Service

1. Make code changes
2. Rebuild and push image:

```bash
$ACR_NAME = "multicontaineracr.azurecr.io"
docker build -t todo-app:v2 ./app
docker tag todo-app:v2 $ACR_NAME/todo-app:v2
docker push $ACR_NAME/todo-app:v2
```

3. Update deployment:

```bash
kubectl set image deployment/todo-app todo-app=$ACR_NAME/todo-app:v2
```

4. Verify:

```bash
kubectl rollout status deployment/todo-app
```

---

## ğŸ’° Cost Optimization

### Scale down when not in use

```bash
# Scale down all deployments
kubectl scale deployment --all --replicas=0

# Scale down nodes
az aks scale \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --node-count 1
```

### Stop cluster (keeps resources but stops billing)

```bash
az aks stop \
  --resource-group multi-container-rg \
  --name multi-container-aks
```

### Start cluster

```bash
az aks start \
  --resource-group multi-container-rg \
  --name multi-container-aks
```

---

## ğŸ”’ Security Best Practices

### Store secrets in Azure Key Vault

```bash
# Create Key Vault
az keyvault create \
  --name multicontainerkv \
  --resource-group multi-container-rg \
  --location eastus

# Store MongoDB password
az keyvault secret set \
  --vault-name multicontainerkv \
  --name mongo-password \
  --value "your-secure-password"
```

Enable Key Vault integration:
```bash
az aks enable-addons \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --addons azure-keyvault-secrets-provider
```

### Enable Network Policies

```bash
az aks update \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --network-policy azure
```

### Use Azure AD Authentication

```bash
az aks update \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --enable-aad \
  --aad-admin-group-object-ids <ADMIN_GROUP_ID>
```

---

## ğŸ§¹ Cleanup / Delete Resources

Delete specific resources:
```bash
# Delete deployments
kubectl delete -f k8s/aks-deployment.yaml
kubectl delete -f k8s/aks-istio-deployment.yaml

# Delete cluster
az aks delete \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --yes --no-wait
```

Delete entire resource group (WARNING: deletes everything):
```bash
az group delete \
  --name multi-container-rg \
  --yes --no-wait
```

---

## ğŸ› Troubleshooting

### Cannot pull images from ACR

Check ACR integration:
```bash
az aks check-acr \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --acr multicontaineracr.azurecr.io
```

Reattach ACR:
```bash
az aks update \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --attach-acr multicontaineracr
```

### Pods not getting sidecar (Istio)

Check namespace label:
```bash
kubectl get namespace default --show-labels
```

Re-label and restart:
```bash
kubectl label namespace default istio.io/rev=asm-1-20 --overwrite
kubectl rollout restart deployment --all
```

### Ingress not working

Check ingress controller:
```bash
# For NGINX
kubectl get pods -n ingress-nginx

# For Istio
kubectl get pods -n aks-istio-ingress
```

Check external IP assignment:
```bash
kubectl get svc -A | grep LoadBalancer
```

### High costs

Check resource usage:
```bash
kubectl top nodes
kubectl top pods

# View pricing
az aks show \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --query 'agentPoolProfiles[].vmSize'
```

---

## ğŸ“Š Comparison: With vs Without Istio

| Feature | Without Istio | With Istio |
|---------|---------------|------------|
| **Setup Complexity** | Simple | Moderate |
| **Resource Usage** | Lower (no sidecars) | Higher (2x pods) |
| **Traffic Management** | Basic (Ingress) | Advanced (retries, circuit breakers) |
| **Security** | Manual TLS | Automatic mTLS |
| **Observability** | Azure Monitor only | Full tracing + metrics |
| **Cost** | Lower | ~20-30% higher |
| **Best For** | Simple apps, cost-sensitive | Production, microservices |

### Side-by-Side Network Comparison

```
WITHOUT ISTIO (Path A)              |    WITH ISTIO (Path B)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Client Request                      |    Client Request
        â†“                           |           â†“
   ALB (Public IP)                  |    ALB (Public IP)
        â†“                           |           â†“
INGRESS-NGINX Controller            |  ISTIO INGRESS GATEWAY
        â†“                           |    (Envoy Proxy)
Service Selection                   |           â†“
        â†“                           |    Gateway + VirtualService
ClusterIP Service                   |    (Advanced Routing)
        â†“                           |           â†“
   Pod (Direct)                     |    ClusterIP Service
   App Container                    |           â†“
   (1/1)                            |    Pod (Sidecar Injection)
        â†“                           |    â”œâ”€ Envoy Proxy
   No Encryption                    |    â””â”€ App Container
   (Local Network)                  |    (2/2)
   Direct TCP/HTTP                  |           â†“
                                    |    Encrypted (mTLS)
                                    |    Sidecar Policies:
                                    |    â”œâ”€ Retry
                                    |    â”œâ”€ Timeout
                                    |    â”œâ”€ Circuit Break
                                    |    â””â”€ Observability
```

### Pod Resource Comparison

```
WITHOUT ISTIO                      |    WITH ISTIO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Pod Memory: ~128-256Mi             |    Pod Memory: ~256-512Mi
Pod CPU: ~100-200m                 |    Pod CPU: ~200-400m
Containers per Pod: 1              |    Containers per Pod: 2
  â”œâ”€ App Container                 |    â”œâ”€ Envoy Proxy (~50MB)
  â””â”€ No overhead                   |    â””â”€ App Container

Network Throughput                 |    Network Throughput
â””â”€ Direct: Full capacity           |    â””â”€ Via Sidecar: ~95-98%

Latency Impact                     |    Latency Impact
â””â”€ Minimal: <1ms                   |    â””â”€ Low: 1-3ms (sidecar)
```

---

## ğŸ†š Migration from Ingress-NGINX to Istio

If you're currently using ingress-nginx:

## ğŸ Quick Reference Commands

```bash
# Connect to cluster
az aks get-credentials --resource-group multi-container-rg --name <CLUSTER_NAME>

# View all resources
kubectl get all --all-namespaces

# View logs
kubectl logs -f <POD_NAME>
kubectl logs -f <POD_NAME> -c istio-proxy  # Istio sidecar logs

# Port forward for testing
kubectl port-forward svc/frontend 8080:80

# Check cluster health
az aks show \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --query 'powerState'

# Update cluster Kubernetes version
az aks upgrade \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --kubernetes-version 1.28.3

# Get cluster credentials again
az aks get-credentials \
  --resource-group multi-container-rg \
  --name multi-container-aks \
  --overwrite-existing
```

---

## ğŸ“š Additional Resources

- [Azure AKS Documentation](https://docs.microsoft.com/en-us/azure/aks/)
- [Azure Service Mesh (Istio)](https://docs.microsoft.com/en-us/azure/aks/istio-about)
- [ACR Documentation](https://docs.microsoft.com/en-us/azure/container-registry/)
- [Azure Monitor for Containers](https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-overview)
- [Azure Pricing Calculator](https://azure.microsoft.com/en-us/pricing/calculator/)

---

## ğŸ”„ Complete Request/Response Lifecycle

### Example: GET http://api.local/todos

```
TIME    SOURCE              ACTION                          DESTINATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

T=0ms   Browser             1. DNS Lookup: api.local
                               â””â”€ Resolves to: 40.xx.xx.xx âœ“

T=5ms   Browser             2. TCP Handshake
                               â””â”€ SYN â†’ ALB:80

T=8ms   ALB                 3. Accept connection
                               â””â”€ SYN-ACK â† Browser

T=12ms  Browser             4. HTTP Request
                               GET /todos HTTP/1.1
                               Host: api.local
                               â””â”€ â†’â†’â†’â†’â†’ ALB

T=15ms  ALB                 5. Route Request
                               â”œâ”€ Check Ingress rule
                               â”œâ”€ Match: host=api.local, path=/
                               â””â”€ Forward to: todo-app service

T=18ms  INGRESS NGINX       6. Service Resolution
                               â”œâ”€ todo-app â†’ ClusterIP:3000
                               â”œâ”€ Lookup service DNS
                               â””â”€ Find backend pods: pod-1, pod-2

T=21ms  INGRESS NGINX       7. Pod Selection (RR)
                               â””â”€ Selected: todo-app-pod-1

T=23ms  INGRESS NGINX       8. Pod Connection
                               â””â”€ Connect to Pod IP:3000

T=28ms  Pod (App)           9. Receive Request
                               â”œâ”€ Parse HTTP request
                               â””â”€ Extract path: /todos

T=32ms  Pod (App)           10. Query Database
                               â”œâ”€ Connect: mongodb://todo-db:27017
                               â”œâ”€ Query: db.todos.find({})
                               â””â”€ Send to MongoDB

T=45ms  MongoDB             11. Execute Query
                               â”œâ”€ Search todos collection
                               â””â”€ Return: [doc1, doc2, ...]

T=48ms  Pod (App)           12. Process Results
                               â”œâ”€ Deserialize BSON
                               â”œâ”€ Convert to JSON
                               â””â”€ Create response body

T=52ms  Pod (App)           13. Send Response
                               HTTP/1.1 200 OK
                               Content-Type: application/json
                               [...todos array...]
                               â””â”€ Send to INGRESS

T=55ms  INGRESS NGINX       14. Forward Response
                               â””â”€ Send to ALB

T=58ms  ALB                 15. Send to Browser
                               â””â”€ HTTP response â†’ Browser

T=62ms  Browser             16. Receive & Render
                               â”œâ”€ Parse JSON response
                               â”œâ”€ Update DOM
                               â””â”€ Display todos list âœ“

TOTAL REQUEST TIME: ~62ms
  â”œâ”€ Network overhead: ~12ms (DNS, TCP, routing)
  â”œâ”€ App processing: ~20ms (request handling)
  â”œâ”€ Database query: ~15ms (query + response)
  â”œâ”€ Serialization: ~8ms (BSON to JSON)
  â””â”€ Ingress overhead: ~7ms (routing, forwarding)
```

### Same Request with Istio (Path B)

```
TIME    SOURCE                  ACTION                      DESTINATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

T=0ms   Browser                 1. DNS Lookup: api.local
                                   â””â”€ Resolves to: 40.yy.yy.yy âœ“

T=5ms   Browser                 2. TCP Handshake
                                   â””â”€ â†’ ISTIO INGRESS GATEWAY:80

T=8ms   ISTIO IG (Envoy)        3. Accept connection
                                   â””â”€ SYN-ACK â† Browser

T=12ms  Browser                 2. HTTP Request
                                   GET /todos HTTP/1.1
                                   â””â”€ â†’â†’â†’â†’â†’ ISTIO IG

T=15ms  ISTIO IG (Envoy)        4. Gateway Processing
                                   â”œâ”€ Match Gateway rule
                                   â”œâ”€ Match: host=api.local
                                   â””â”€ Route: VirtualService

T=18ms  ISTIO IG (Envoy)        5. VirtualService Policy
                                   â”œâ”€ Check retry policy: attempts=3
                                   â”œâ”€ Check timeout: 10s
                                   â”œâ”€ Check circuit breaker
                                   â””â”€ Select destination: todo-app

T=21ms  ISTIO IG (Envoy)        6. Service Resolution
                                   â”œâ”€ Load balance: pod-1 or pod-2
                                   â””â”€ Selected: todo-app-pod-1

T=23ms  ISTIO IG (Envoy)        7. Initiate mTLS
                                   â”œâ”€ TLS handshake start
                                   â””â”€ Encrypt connection

T=28ms  todo-app SIDECAR        8. Receive Encrypted
                                   â”œâ”€ mTLS established
                                   â”œâ”€ Decrypt request
                                   â”œâ”€ Check authorization (AUTHZ)
                                   â””â”€ Forward to app container

T=32ms  Pod (App)               9. Receive Request
                                   â”œâ”€ Parse HTTP request
                                   â””â”€ Extract path: /todos

T=35ms  Pod (App)               10. Query Database
                                   â”œâ”€ Connect: mongodb://todo-db:27017
                                   â””â”€ Send query

T=48ms  MongoDB                 11. Execute Query
                                   â””â”€ Return: [doc1, doc2, ...]

T=51ms  Pod (App)               12. Process Results
                                   â””â”€ Convert to JSON

T=54ms  Pod (App)               13. Send Response
                                   â””â”€ Response body ready

T=55ms  todo-app SIDECAR        14. Sidecar Egress
                                   â”œâ”€ Collect metrics
                                   â”œâ”€ Latency so far: 42ms
                                   â”œâ”€ Request count: +1
                                   â””â”€ Forward to IG

T=58ms  ISTIO IG (Envoy)        15. Forward Response
                                   â”œâ”€ Collect metrics
                                   â””â”€ Send to browser

T=62ms  Browser                 16. Receive & Render
                                   â””â”€ Display todos list âœ“

TOTAL REQUEST TIME: ~62-65ms
  â”œâ”€ Network overhead: ~12ms
  â”œâ”€ mTLS encryption: ~5-8ms (extra)
  â”œâ”€ Sidecar processing: ~3-5ms (extra)
  â”œâ”€ App processing: ~20ms
  â”œâ”€ Database query: ~15ms
  â””â”€ Serialization: ~8ms

OVERHEAD FROM ISTIO: ~5-10ms (~8-15% additional latency)
BENEFITS: Enhanced observability, security, policy enforcement
```

---

ğŸŠ **Your multi-container application is now running on Azure AKS!**

Choose the deployment path that matches your requirements:
- **Path A (Without Istio)**: Simpler, cheaper, good for basic apps
- **Path B (With Istio)**: Advanced features, better for production microservices
